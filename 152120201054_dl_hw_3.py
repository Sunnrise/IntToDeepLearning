# -*- coding: utf-8 -*-
"""152120201054_DL_HW-3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OSdjOszW-zzgjdfB3PBjdTnpFERbC0hq
"""

import zipfile

# Fırsly I added a zipfile from computer.
zip_path = '/content/HW3_percep.zip'

# Specify the extraction directory
extraction_path = '/content/extracted_folder/'

# Extract the ZIP file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extraction_path)
    # /content/extracted_folder/CaltechTinySplit then I carry files from here to main folder list (test and train)

# prompt: how to import netron on colab

!pip install netron

import os
from PIL import Image
import numpy as np
import cv2

main_folder = "/content/extracted_folder/CaltechTinySplit/train"
test_folder = "/content/extracted_folder/CaltechTinySplit/test"
classes = ["flamingo", "pizza"]

# Training Data
train_data = []
train_labels = []

for i, class_name in enumerate(classes):
    class_folder = os.path.join(main_folder, class_name)
    for filename in os.listdir(class_folder):
        img_path = os.path.join(class_folder, filename)
        img = cv2.imread(img_path)
        resized_img = cv2.resize(img, (128, 128)).flatten()  # Resize to 128x128x3 and flatten
        train_data.append(resized_img)
        train_labels.append(i)  # Assign label based on the class index

# Convert lists to numpy arrays
train_data = np.array(train_data)
train_labels = np.array(train_labels)

# 'train_data' now contains the flattened image data (1x49152), and 'train_labels' contains the corresponding class labels.

# Testing Data
test_data = []
test_labels = []

for i, class_name in enumerate(classes):
    class_folder = os.path.join(test_folder, class_name)
    for filename in os.listdir(class_folder):
        img_path = os.path.join(class_folder, filename)
        img = cv2.imread(img_path)
        resized_img = cv2.resize(img, (128, 128)).flatten()  # Resize to 128x128x3 and flatten
        test_data.append(resized_img)
        test_labels.append(i)  x

# Convert the test data list to a numpy array
test_data = np.array(test_data)
test_labels = np.array(test_labels)

# 'test_data' now contains the flattened test image data (1x49152), and 'test_labels' contains the corresponding class labels.

import numpy as np
from sklearn.utils import shuffle

# Mish aktivasyon fonksiyonunu ve türevini tanımlayın
np.warnings.filterwarnings(
    'ignore',
    category=RuntimeWarning
)
def tanh(x):
    return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))

def softplus(x):
    return np.log(1 + np.exp(x))

def mish(x):
    return x * tanh(softplus(x))

def dmish(x):
    omega = np.exp(3*x) + 4*np.exp(2*x) + (6+4*x)*np.exp(x) + 4*(1 + x)
    delta = 1 + pow((np.exp(x) + 1), 2)
    derivative = np.exp(x) * omega / pow(delta, 2)
    return derivative

# Perceptron modelini tanımlamak
def trainPerceptron(train_data, train_labels, weights, rho, iterNo):
    # Bias eklemek
    train_data = np.column_stack((np.ones(len(train_data)), train_data))

    # Girişleri ve etiketleri shuffle yapmak
    train_data, train_labels = shuffle(train_data, train_labels, random_state=42)

    for iteration in range(iterNo):
        for i in range(len(train_data)):
            # Tahmini hesaplamak
            prediction = np.dot(weights, train_data[i])
            y_pred = mish(prediction)

            # Ağırlıkları güncellemek
            weights += rho * (train_labels[i] - y_pred) * dmish(prediction) * train_data[i]

    # Eğitilmiş ağırlıkları kaydetmek
    np.save('weights.npy', weights)

    return weights

# Örnek kullanım:
# 'inputs', 'train_labels', 'weights', 'rho' ve 'iterNo' tanımlanmış olduğunu varsayalım.
# Ağırlıkları rastgele başlatırız
initial_weights = np.random.rand(train_data.shape[1] + 1)

# Perceptronu eğitiriz
trained_weights = trainPerceptron(train_data, train_labels, initial_weights, 0.00001, 300)

import numpy as np
from sklearn.metrics import accuracy_score

# Mish aktivasyon fonksiyonunu tanım
def mish(input):
    return input * np.tanh(np.log1p(np.exp(input)))

# Perceptron modelini test etmek için bir fonksiyon tanımlayalım
def testPerceptron(test_data, test_labels, weights):
    # Bias eklemek
    test_data = np.column_stack((np.ones(len(test_data)), test_data))

    # Tahminleri saklamak için bir dizi oluştur
    predictions = []

    for i in range(len(test_data)):
        # Tahmini hesapla
        prediction = np.dot(weights, test_data[i])
        y_pred = 1 if mish(prediction) >= 0 else 0

        # Tahminleri sakla
        predictions.append(y_pred)

    # Doğruluk skorunu hesapla
    accuracy = accuracy_score(test_labels, predictions)

    return accuracy

# Örnek kullanım:
# 'test_data', 'test_labels' ve 'weights' tanımlanmış olduğunu varsayalım.

# Ağırlıkları yükle
weights = np.load('weights.npy')

# Perceptronu test et
accuracy = testPerceptron(test_data, test_labels, weights)

print(f"Doğruluk: {accuracy}")